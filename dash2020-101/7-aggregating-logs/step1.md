Make sure you wait for the **Provisioning Complete** message in the terminal before opening the IDE or the application. 

1.  In the IDE, open `docker-compose-files/docker-compose.yaml`.
2.  As you can see, Logs collection has already been enabled for our application. You can see this by looking at the `environment` section for each service and finding the two `DD_LOGS` variables.
3.  Then you can see that labels have been added for auto discovery to enable logs to be collected and categorized.
4.  Now whatever logs are generated by the services are forwarded to Datadog. 
5.  Let's run **gor** again to get some traffic going on our site. `./gor --input-file-loop --input-file requests_0.gor --output-http "http://localhost:3000"`{{execute}}
6.  Open Datadog and navigate to **Logs**.
7.  Right away we can see logs are being collected and displayed. 
8.  On the left side of the window under **Service** you see each of the services listed. This was generated based on our auto discovery labels. 
9.  Hover over each one. Notice that to the right of whichever one you are hovering over, you see the word **Only**, meaning that if you click here you will Only see that services logs. 
10. Click on **store-frontend**, then try each of the others to see the list of logs update.
11. If you click on the currently selected service, it will go back to showing everything. 
12. Under Source just above that you can see that you can filter based on **ruby**, **python**, or the **agent**. Most of the other **facets** don't apply to our logs.
13. Try clicking on some of the log lines. Notice the details panel that comes out. Depending on the source of the logs, more detail may be displayed here.
14. Switch over to the Patterns view. You can do this by clicking the second icon under **Log Explorer**.
15. When you have thousands of log lines, many of them will look very similar to each other. The Patterns view will pluck out the common patterns in your logs allowing you to see a higher level aggregate.
16. Click on any one of the Patterns to see all the logs with that pattern.
17. Finally there is the Graph view that allows you to visualize the quantity of lines that match your query.
18. As new logs get ingested by Datadog it can be a few seconds before they appear in the Search view. Switching to Live Tail
19. You might be wondering how we know how to parse any of these lines. From the **Logs** menu, navigate to **Configuration**.
20. The Pipelines are the configuration for each type of log. Click on a Pipeline to see the configuration. Then click on each Parser and Remapper to see how they are configured. In the Rules section, you can click the question mark to learn more.